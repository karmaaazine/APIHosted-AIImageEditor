#!/bin/bash

echo "ðŸš€ Starting AI Image Editor API..."
echo "ðŸ“ Powered by RealVisXL_V5.0 - Professional AI Image Editing"
echo ""

# Check Python version
python_version=$(python3 --version 2>&1 | grep -oP '(?<=Python )\d+\.\d+' || echo "unknown")
echo "ðŸ Python version: $python_version"

# Check if CUDA is available
if command -v nvidia-smi &> /dev/null; then
    echo "ðŸŽ® GPU Status:"
    nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv,noheader,nounits | while read line; do
        echo "   ðŸ“± $line"
    done
else
    echo "âš ï¸  No NVIDIA GPU detected - will run on CPU (slower)"
fi

echo ""
echo "ðŸ“¦ Installing Python dependencies..."
pip install -r requirements.txt

echo ""
echo "ðŸ¤– Checking and downloading AI models..."
echo "   ðŸ“¥ This may take 5-15 minutes on first run (~6GB download)"
echo "   ðŸ’¾ Models will be cached for future use"
echo ""

# Create a Python script to download and verify models
cat > download_models.py << 'EOF'
import sys
import torch
from diffusers import AutoPipelineForInpainting, StableDiffusionXLPipeline
from huggingface_hub import snapshot_download
import os

MODEL_NAME = "SG161222/RealVisXL_V5.0"
MODEL_CONFIG = {
    "torch_dtype": torch.float16,
    "variant": "fp16"
}

def check_disk_space():
    """Check if we have enough disk space for the model"""
    try:
        import shutil
        total, used, free = shutil.disk_usage('/')
        free_gb = free // (1024**3)
        print(f"   ðŸ’½ Available disk space: {free_gb}GB")
        if free_gb < 10:
            print(f"   âš ï¸  Warning: Low disk space. Need ~10GB free, have {free_gb}GB")
            return False
        return True
    except Exception as e:
        print(f"   âš ï¸  Could not check disk space: {e}")
        return True

def download_model_files():
    """Download model files using huggingface_hub for better progress tracking"""
    try:
        print(f"   ðŸ“¥ Downloading {MODEL_NAME}...")
        
        # Download model files with progress
        cache_dir = snapshot_download(
            repo_id=MODEL_NAME,
            cache_dir=None,  # Use default cache
            local_files_only=False,
            revision=None
        )
        
        print(f"   âœ… Model files downloaded to: {cache_dir}")
        return True
        
    except Exception as e:
        print(f"   âŒ Error downloading model files: {e}")
        return False

def verify_inpainting_pipeline():
    """Verify inpainting pipeline can be loaded"""
    try:
        print("   ðŸ”§ Verifying inpainting pipeline...")
        
        # Try to load without moving to GPU to save memory during verification
        pipe = AutoPipelineForInpainting.from_pretrained(
            MODEL_NAME,
            **MODEL_CONFIG,
            device_map=None  # Don't auto-assign to GPU yet
        )
        
        print("   âœ… Inpainting pipeline verified")
        del pipe  # Free memory
        return True
        
    except Exception as e:
        print(f"   âŒ Error verifying inpainting pipeline: {e}")
        return False

def verify_text2img_pipeline():
    """Verify text-to-image pipeline can be loaded"""
    try:
        print("   ðŸ”§ Verifying text-to-image pipeline...")
        
        # Try to load without moving to GPU
        pipe = StableDiffusionXLPipeline.from_pretrained(
            MODEL_NAME,
            **MODEL_CONFIG,
            device_map=None  # Don't auto-assign to GPU yet
        )
        
        print("   âœ… Text-to-image pipeline verified")
        del pipe  # Free memory
        return True
        
    except Exception as e:
        print(f"   âŒ Error verifying text-to-image pipeline: {e}")
        return False

def main():
    print("ðŸ¤– AI Model Download and Verification")
    print(f"   ðŸ“‹ Model: {MODEL_NAME}")
    print(f"   ðŸ”§ Config: {MODEL_CONFIG}")
    print("")
    
    # Check disk space
    if not check_disk_space():
        print("   âš ï¸  Proceeding anyway, but monitor disk space...")
    
    # Download model files first
    print("ðŸ“¥ Step 1: Downloading model files...")
    if not download_model_files():
        print("âŒ Failed to download model files")
        sys.exit(1)
    
    print("")
    print("ðŸ”§ Step 2: Verifying pipelines...")
    
    # Verify inpainting pipeline
    if not verify_inpainting_pipeline():
        print("âŒ Failed to verify inpainting pipeline")
        sys.exit(1)
    
    # Clear any cached models and verify text-to-image
    torch.cuda.empty_cache() if torch.cuda.is_available() else None
    
    if not verify_text2img_pipeline():
        print("âŒ Failed to verify text-to-image pipeline")
        sys.exit(1)
    
    # Final cleanup
    torch.cuda.empty_cache() if torch.cuda.is_available() else None
    
    print("")
    print("ðŸŽ‰ All models downloaded and verified successfully!")
    print("   ðŸ’¾ Models are cached and ready for use")
    print("   ðŸš€ API startup will now be much faster")
    
if __name__ == "__main__":
    main()
EOF

# Run the model download script
echo "ðŸ”„ Running model download and verification..."
python download_models.py

# Check if download was successful
if [ $? -ne 0 ]; then
    echo ""
    echo "âŒ Model download failed!"
    echo "   ðŸ”§ Troubleshooting tips:"
    echo "   â€¢ Check internet connection"
    echo "   â€¢ Verify HuggingFace Hub access"
    echo "   â€¢ Ensure sufficient disk space (~10GB)"
    echo "   â€¢ Try running: pip install --upgrade diffusers transformers"
    echo ""
    echo "ðŸ”„ Starting API anyway (models will download on first request)..."
else
    echo ""
    echo "âœ… Models ready! Starting API server..."
fi

# Clean up download script
rm -f download_models.py

echo ""
echo "ðŸ”¥ Features Available:"
echo "   ðŸŽ¨ AI Inpainting - Replace/modify objects in images"
echo "   ðŸ—‘ï¸  Object Removal - Seamlessly erase unwanted objects"
echo "   âœ¨ Text-to-Image - Generate images from text prompts"
echo ""
echo "ðŸ’¡ Memory Optimization:"
echo "   â€¢ Models load on-demand to optimize GPU memory"
echo "   â€¢ Smart unloading prevents CUDA OOM errors"
echo "   â€¢ Real-time memory monitoring included"
echo ""
echo "ðŸŒ API will be available at: http://localhost:8000"
echo "ðŸ“– API docs will be at: http://localhost:8000/docs"
echo ""
echo "â³ Starting FastAPI server..."
echo "   (Models are pre-downloaded, first request should be fast!)"
echo ""

python main.py